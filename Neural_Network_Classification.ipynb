{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2IkRbDCjwoGMtw0rKV4rf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sambaran04/Tensorflow/blob/main/Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Classification\n",
        "\n",
        "In this notebook we're going to learn how to write neural networks for classificatio problem.\n",
        "\n",
        "A classification is where you try to classify\n",
        "something as one thing or another\n",
        "\n",
        "A few types of classification problems:\n",
        "* Binary Classification\n",
        "* Multiclass Classification\n",
        "* Multilabel Classification"
      ],
      "metadata": {
        "id": "mxcmqRbzIr3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "HwEPmBAJObft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data to view and fit"
      ],
      "metadata": {
        "id": "buON-NkcL6yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Make 1000 examples\n",
        "n_samples =1000\n",
        "\n",
        "# Create circles\n",
        "X, y = make_circles(n_samples,\n",
        "                    noise=0.03,\n",
        "                    random_state=42)"
      ],
      "metadata": {
        "id": "oR_plKi1BNmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out features\n",
        "X"
      ],
      "metadata": {
        "id": "nk64zDJnBeM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the labels\n",
        "y[:10]"
      ],
      "metadata": {
        "id": "KH6VsvcjByJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = tf.cast(X, tf.float32)\n",
        "# y = tf.cast(y, tf.float32)"
      ],
      "metadata": {
        "id": "sLvyu4NbQOkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "circles = pd.DataFrame({\"X0\":X[:, 0], \"X\":X[:,1], \"label\":y})\n",
        "circles"
      ],
      "metadata": {
        "id": "FVmxBmC1B1Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize with a plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X[:, 0], X[:,1], c=y, cmap=plt.cm.RdYlBu)"
      ],
      "metadata": {
        "id": "YxBX_lqNEo7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input & Output Shapes"
      ],
      "metadata": {
        "id": "fqDNVr4fFFeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes of our features and labels\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "9ZfOSdMJF1C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples we're working\n",
        "len(X), len(y)"
      ],
      "metadata": {
        "id": "0qU6Oz_BF8LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first example of features and labels\n",
        "X[0], y[0]"
      ],
      "metadata": {
        "id": "qcKdEAKlF_Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling\n",
        "\n",
        "The steps in modelling with TensorFlow are typically:\n",
        "\n",
        "1. Create or import a model\n",
        "2. Compile the model\n",
        "3. Fit the model\n",
        "4. Evaluate the model\n",
        "5. Tweak\n",
        "6. Evaluate..."
      ],
      "metadata": {
        "id": "coZ6JsOZGFIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(X, y, epochs=200, verbose=0)\n",
        "model_1.evaluate(X, y)"
      ],
      "metadata": {
        "id": "Bw2lkRS0OUAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "\n",
        "Let's look into our bag of trics to see how we can improve our model.\n",
        "  1. Create a model- we might to add more layers or increase the number of hidden units within a layer.\n",
        "  2. Compiling a model- here we might to choose a different optimization function such as Adam instead of SGD.\n",
        "  3. Fitting a model- perhaps we might fit our model for more epochs (leave it training for longer)."
      ],
      "metadata": {
        "id": "qupnI_OYOYiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (this time 3 layers)\n",
        "model_2 = tf.keras.Sequential([\n",
        "  # Before TensorFlow 2.7.0\n",
        "  # tf.keras.layers.Dense(100), # add 100 dense neurons\n",
        "\n",
        "  # With TensorFlow 2.7.0\n",
        "  # tf.keras.layers.Dense(100, input_shape=(None, 1)), # add 100 dense neurons\n",
        "\n",
        "  ## After TensorFlow 2.8.0 ##\n",
        "  tf.keras.layers.Dense(100), # add 100 dense neurons\n",
        "  tf.keras.layers.Dense(10), # add another layer with 10 neurons\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(), # use Adam instead of SGD\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(X, y, epochs=100, verbose=0) # fit for 100 passes of the data\n",
        "model_2.evaluate(X, y)"
      ],
      "metadata": {
        "id": "r5h3R-lZSpNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize our model's predictions, let's create a function `plot_decision_boundary()`, this function will:\n",
        "\n",
        "* Take in a trained model, features (X) and labels (y)\n",
        "* Create a meshgrid of the different X values\n",
        "* Make predictions across the meshgrid\n",
        "* Plot the predictions as well as a line between zones (Where each unique class falls)"
      ],
      "metadata": {
        "id": "qcNt_ghITMHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def plot_decision_boundary(model, X, y):\n",
        "  \"\"\"\n",
        "  Plots the decision boundary created by a model predicting on X.\n",
        "  \"\"\"\n",
        "  # Define the axis boundaries of the plot and create a meshgrid\n",
        "  x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() +0.1\n",
        "  y_min, y_max = X[:, 0].min() - 0.1, X[:, 0].max() +0.1\n",
        "  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                       np.linspace(y_min, y_max, 100))\n",
        "\n",
        "  # Create X value (we're going to make predictions on these)\n",
        "  x_in = np.c_[xx.ravel(), yy.ravel()] # Stack 2D arrays together\n",
        "\n",
        "  # Make predictions\n",
        "  y_pred = model.predict(x_in)\n",
        "\n",
        "  # Check for multi class\n",
        "  if len(y_pred[0])>1:\n",
        "    print(\"Doing multiclass classification\")\n",
        "    # We have to reshape our prediction to get them ready for plotting\n",
        "  else:\n",
        "    print(\"Doing binary classificaion\")\n",
        "    y_pred = np.round(y_pred).reshape(xx.shape)\n",
        "\n",
        "  # Plot the decision boundary\n",
        "  plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.ylim(yy.min(), yy.max())"
      ],
      "metadata": {
        "id": "6il7fQRDvP34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model=model_2,\n",
        "                       X=X,\n",
        "                       y=y)"
      ],
      "metadata": {
        "id": "RfwECnwxwctJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Recreate the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Change the loss and metrics of our compiled model\n",
        "model_3.compile(loss=tf.keras.losses.mae, # change the loss function to be regression-specific\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['mae']) # change the metric to be regression-specific\n",
        "\n",
        "# Fit the recompiled model"
      ],
      "metadata": {
        "id": "BehK8f-o3IwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create some regression data\n",
        "X_regression = np.arange(0, 1000, 5)\n",
        "y_regression = np.arange(100, 1100, 5)\n",
        "\n",
        "# Split it into training and test sets\n",
        "X_reg_train = X_regression[:150]\n",
        "X_reg_test = X_regression[150:]\n",
        "y_reg_train = y_regression[:150]\n",
        "y_reg_test = y_regression[150:]\n",
        "\n",
        "# Fit our model to the data\n",
        "# Note: Before TensorFlow 2.7.0, this line would work\n",
        "# model_2.fit(X_reg_train, y_reg_train, epochs=100)\n",
        "\n",
        "# After TensorFlow 2.7.0, see here for more: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/278\n",
        "model_3.fit(tf.expand_dims(X_reg_train, axis=-1),\n",
        "            y_reg_train,\n",
        "            epochs=100, verbose=0)\n",
        "model_3.evaluate(X_reg_train, y_reg_train)"
      ],
      "metadata": {
        "id": "g3URHFuR25K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our trained model\n",
        "y_reg_preds = model_3.predict(X_reg_test)\n",
        "\n",
        "# Plot the model's predictions against our regression data\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(X_reg_train, y_reg_train, c=\"b\", label=\"Training data\")\n",
        "plt.scatter(X_reg_test, y_reg_test, c=\"g\", label=\"Testing data\")\n",
        "plt.scatter(X_reg_test, y_reg_preds, c=\"r\", label=\"Predictions\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "VL25RGvh2_UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The missing piece: Non-Linearity"
      ],
      "metadata": {
        "id": "5sGaDpOP4OBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.linear), # 1 hidden layer with linear activation\n",
        "  tf.keras.layers.Dense(1) # output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # note: \"lr\" used to be what was used, now \"learning_rate\" is favoured\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model_4.fit(X, y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "hW0K7FoY4vWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our data\n",
        "plt.scatter(X[:, 0], X[:,1], c=y, cmap=plt.cm.RdYlBu)"
      ],
      "metadata": {
        "id": "JwlO8Z37iPX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model=model_4,\n",
        "                       X=X,\n",
        "                       y=y)"
      ],
      "metadata": {
        "id": "1C2Jd-_96XIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model with a non-linear activation\n",
        "model_5 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.relu), # can also do activation='relu'\n",
        "  tf.keras.layers.Dense(1) # output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model_5.fit(X, y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "ieJqINqc3nty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model=model_5,\n",
        "                       X=X,\n",
        "                       y=y)"
      ],
      "metadata": {
        "id": "u_kaABgt8yQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model with a non-linear activation\n",
        "model_6 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),# can also do activation='relu'\n",
        "  tf.keras.layers.Dense(1) # output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.03),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model_6.fit(X, y, epochs=200, verbose=0)\n",
        "model_6.evaluate(X, y)"
      ],
      "metadata": {
        "id": "0WBlPlo_9LSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model=model_6,\n",
        "                       X=X,\n",
        "                       y=y)"
      ],
      "metadata": {
        "id": "tg9ed9aQBvmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model\n",
        "model_7 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, ReLU activation\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n",
        "  # hidden layer 2, ReLU activation\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # ouput layer, sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model_7.fit(X, y, epochs=100, verbose=0)\n",
        "model_7.evaluate(X, y)"
      ],
      "metadata": {
        "id": "tpt-RR9DACcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model=model_7,\n",
        "                       X=X,\n",
        "                       y=y)"
      ],
      "metadata": {
        "id": "zgeYBdu6BsRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating and improving our classification\n",
        "\n",
        "So far we've been training and testing on the same dataset...\n",
        "However, in machine learning this is basically a sin.\n",
        "So let's create a training and test set"
      ],
      "metadata": {
        "id": "TX2KnlWoB1ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many examples we have\n",
        "len(X)"
      ],
      "metadata": {
        "id": "R4lo3TokfQ_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "_u8U4zKWfXmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "5oFS_HMbfu3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's recreate a model to fit on the trainiing data and evaluate on the testing data\n",
        "\n",
        "# Create a model\n",
        "model_8 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, ReLU activation\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n",
        "  # hidden layer 2, ReLU activation\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # ouput layer, sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_8.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model_8.fit(X_train, y_train, epochs=500, verbose=0)\n",
        "model_8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "rO6PLHPMf2va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundaries for the training and test sets\n",
        "\n",
        "plt.figure(figsize=[12, 6])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(model_8, X_train, y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(model_8, X_test, y_test)"
      ],
      "metadata": {
        "id": "4x551N2WgW_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the best learning rate\n",
        "\n",
        "To find the ideal learning rate (the learning rate where the loss decreases the most during training) we're going to use the following steps:\n",
        "* A learning rate **callback** - you can think of a callback as an extra piece of funtionality, you can add to your model while it's training\n",
        "* Another model (We Could use the same one as above, but we're practicing building models here)\n",
        "* A modified loss curves plot."
      ],
      "metadata": {
        "id": "18aqgwUihhVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's recreate a model to fit on the trainiing data and evaluate on the testing data\n",
        "\n",
        "# Create a model\n",
        "model_9 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, ReLU activation\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n",
        "  # hidden layer 2, ReLU activation\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # ouput layer, sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "                metrics=['accuracy'])\n",
        "# Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20))\n",
        "# Fit the model (passing lr_scheduler callback)\n",
        "history = model_9.fit(X_train, y_train, epochs=100, callbacks=[lr_scheduler], verbose=0)\n",
        "model_9.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "wSWoPtS8k995"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkout the history\n",
        "pd.DataFrame(history.history).plot(figsize=(10, 7), xlabel=\"epochs\")"
      ],
      "metadata": {
        "id": "8IVC_tMRmjAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate versus the loss\n",
        "lrs = 1e-4 * (10 ** (tf.range(100)/20))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history.history[\"loss\"])\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs Loss\")"
      ],
      "metadata": {
        "id": "oEhe6ILNm7p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of other typical learning rates values:\n",
        "10**0, 10**-1, 10**-2, 10**-3, 1e-4"
      ],
      "metadata": {
        "id": "PiDptZIvpUdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try using a higher *ideal* learning rate with the same model as before\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "# Create a model\n",
        "model_10 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 1, ReLU activation\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n",
        "  tf.keras.layers.Dense(4, activation=tf.keras.activations.relu), # hidden layer 2, ReLU activation\n",
        "  tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) # ouput layer, sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_10.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(lr=0.2),\n",
        "                metrics=['accuracy'])\n",
        "# Create a learning rate callback\n",
        "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20))\n",
        "# Fit the model (passing lr_scheduler callback)\n",
        "history = model_10.fit(X_train, y_train, epochs=300, verbose=0)\n",
        "model_10.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "K_e8AiWn8DXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundaries for the training and test sets\n",
        "\n",
        "plt.figure(figsize=[12, 6])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(model_10, X_train, y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(model_10, X_test, y_test)"
      ],
      "metadata": {
        "id": "pggP1cfX8zis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More classificaiton evaluation methods\n",
        "\n",
        "Alongside visualizing our models results a much as possible, there are a handful of other classification evaluation methods & metrics you should be familiar with:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-Score\n",
        "* Confusion matrix\n",
        "* Classification report (from sklearn)"
      ],
      "metadata": {
        "id": "QvkPNRw0-jsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the accuracy of our model\n",
        "loss, accuracy = model_10.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss:.2f}\")\n",
        "print(f\"Model accuracy on the test set: {(accuracy*100):.2f}%\")"
      ],
      "metadata": {
        "id": "vrqksjKT6LKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_preds[:10]"
      ],
      "metadata": {
        "id": "69iudIUI-Sry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Create a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        " # Make predictions\n",
        "y_preds = model_10.predict(X_test)\n",
        "\n",
        "# Convert prediction probabilities to binary format and view the first 10\n",
        "# y_preds = tf.round(y_preds)[:10]\n",
        "\n",
        " # Create confusion matrix\n",
        "confusion_matrix(y_test, tf.round(y_preds))"
      ],
      "metadata": {
        "id": "m-G4mQiU8S-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we prettif our confusion matrix?"
      ],
      "metadata": {
        "id": "tDfurWEW-A3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "figsize = (10, 10)\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, tf.round(y_preds))\n",
        "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize our confusion Matrix\n",
        "n_classes = cm.shape[0]\n",
        "\n",
        "# Let's prettify it\n",
        "fig, ax = plt.subplots(figsize = figsize)\n",
        "\n",
        "# Create a matrix plot\n",
        "cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# Create classes\n",
        "classes = False\n",
        "\n",
        "if classes:\n",
        "  labels = classes\n",
        "else:\n",
        "  labels = np.arange(cm.shape[0])\n",
        "\n",
        "# Label the axes\n",
        "ax.set(title=\"Confusion Matrix\",\n",
        "       xlabel=\"Predicted Label\",\n",
        "       ylabel=\"True Label\",\n",
        "       xticks = np.arange(n_classes),\n",
        "       yticks = np.arange(n_classes),\n",
        "       xticklabels=labels,\n",
        "       yticklabels=labels)\n",
        "\n",
        "# Set x-axis labels to bottom\n",
        "ax.xaxis.set_label_position(\"bottom\")\n",
        "ax.xaxis.tick_bottom()\n",
        "\n",
        "# Adjst label size\n",
        "ax.yaxis.label.set_size(20)\n",
        "ax.xaxis.label.set_size(20)\n",
        "ax.title.set_size(20)\n",
        "\n",
        "# Set threshold for different colors\n",
        "threshold = (cm.max()+cm.min())\n",
        "\n",
        "# Plot the text on each cell\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "  plt.text(j, i, f\"{cm[1, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "           horizontalalignment='center',\n",
        "           color = 'white' if cm[i, j]>threshold else \"black\",\n",
        "           size=15)"
      ],
      "metadata": {
        "id": "1C6ADauV0PgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with a larger example (multiclass classification)\n",
        "\n",
        "When you have more that two classes as an option, it's known as **multi-class classification**.\n",
        "* This means if you have 3 different classes, it's multi-class classification.\n",
        "* It also means if you have 100 different classes, it's multi-class classification.\n",
        "To practice multi-class classification, we're going to build a neural network to classify images of different items"
      ],
      "metadata": {
        "id": "Md2p4bnH1Fav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import tensorflow as tf\n",
        " from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        " # The data has already been sorted into training and test sets for us\n",
        " (train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "clD5zrsRrLYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpSW_iYiuoPA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}