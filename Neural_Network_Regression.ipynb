{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiBgz2oe40y2Q8KzP8rFa6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sambaran04/Tensorflow/blob/main/Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Regression with Neural Network in TensorFlow**\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we're going to simplify it: Predicting a numerical variable based on some other combination of variables, even shorter... predicting a number."
      ],
      "metadata": {
        "id": "S7iiMn1sP70a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TenforFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "doPkz2Z528FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TQfRVstgJudp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "id": "POER2scBJ1ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y == X+10"
      ],
      "metadata": {
        "id": "wYVflYW7KS2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes"
      ],
      "metadata": {
        "id": "qVLLa2yTKr01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a debo tensor for our housing price prediciton problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "id": "Iw9TaSWJKu4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].shape, y[0].shape"
      ],
      "metadata": {
        "id": "laZAZxi4LoIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.constant(X)\n",
        "y = tf.constant(y)"
      ],
      "metadata": {
        "id": "k1DewfXBQZ3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "id": "oqVtcte0Qk2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "1. **Creating a model**- define the inpur and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model**- define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to imporve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model**- letting the model try to find patterns between X & y (features and labels)."
      ],
      "metadata": {
        "id": "7cV8kSbHQmtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, y, epochs=5)"
      ],
      "metadata": {
        "id": "9evxwGTnVvg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our model\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "id": "kyKcYGrzYOJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our Model"
      ],
      "metadata": {
        "id": "SEyPWU2farOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "# model.fit(X, y, epochs=1000)"
      ],
      "metadata": {
        "id": "Pqttfw9xC1ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "id": "RIwwDPJ-Qn1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved...\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "id": "a_dWcvkR_ZIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we can make another to improve our model\n",
        "\n",
        "# 1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "# model.fit(X, y, epochs=1000)"
      ],
      "metadata": {
        "id": "Yzm0gBdf_hnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved...\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "id": "mS_cIuCRCBbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model\n",
        "\n",
        "In practice, a typical workflow you'll go through when builidng neural network is:\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> twea a model -> fit it -> evaluate it...\n",
        "```"
      ],
      "metadata": {
        "id": "_0AyKT1hC63t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluation... there are 3 words we should memorize:\n",
        "\n",
        "> \"Visualize, Visualize, Visualize\"\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* The data - what data are we working with? What does it look like?\n",
        "* The model itself - what does our model look like?\n",
        "* The training of a model - how does a model perform while it learns?\n",
        "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)"
      ],
      "metadata": {
        "id": "COLtfR9w3fJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset:\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "metadata": {
        "id": "jeaDkHx24-86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset\n",
        "y = X+10\n",
        "y"
      ],
      "metadata": {
        "id": "1K1kXCUg5FRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "id": "XkgK22cD5Ql7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### There are 3 Sets...\n",
        "\n",
        "* Training set - the model learns from this data, which is typically 70-80% of the total data you have available.\n",
        "* Validation set - The model gets tuned on this data, which is typcically 10-15% of the data available.\n",
        "* Test set - The model gets evaluated on this data to test what it has learnt, this set is typically 10-15% of the data available."
      ],
      "metadata": {
        "id": "7W1jdB-S5Zft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "metadata": {
        "id": "M7puUGBS69V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 are testing samples (20% of the data)\n",
        "y_test = y[40:]"
      ],
      "metadata": {
        "id": "iz7rSD7u7N-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Now we've got our data in training and test sets... let's visualize it again"
      ],
      "metadata": {
        "id": "wq4y4IH18Dwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label = \"Training dataset\")\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"r\", label = \"Test dataset\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "dBmBOOh_8L1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we can make another to improve our model\n",
        "\n",
        "# 1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X_train, y_train, epochs=1000)"
      ],
      "metadata": {
        "id": "wxw1Ismw8rfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "r7MA5JbGkcUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_fine = np.array(y_test)\n",
        "y_test_fine"
      ],
      "metadata": {
        "id": "VmSOhFrAkrHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "ZdUmcSpfkwKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hello World\")"
      ],
      "metadata": {
        "id": "2vyCNF3doH3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e5hkE_4fJW4p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}